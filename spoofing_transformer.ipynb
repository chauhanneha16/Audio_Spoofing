{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNnEZedyNCYh8EB0513A+cZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chauhanneha16/Audio_Spoofing/blob/main/spoofing_transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MB2s-nAVYVxt"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "zDzj8yrRYmb9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%env KAGGLE_CONFIG_DIR=/root/.kaggle/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVJ7sSdWfB4y",
        "outputId": "4d2c4711-fd15-450f-bc28-3b6a5db88d54"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: KAGGLE_CONFIG_DIR=/root/.kaggle/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/asvpoof-2019-dataset.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "cRFdeI3IZo56"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "lJjfrcWfe8vt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths and parameters\n",
        "DATASET_PATH = \"/content/LA/LA/ASVspoof2019_LA_eval/flac\"\n",
        "LABEL_FILE_PATH = \"/content/LA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt\"\n",
        "NUM_CLASSES = 2  # Number of classes (bonafide and spoof)\n",
        "SAMPLE_RATE = 16000  # Sample rate of your audio files\n",
        "DURATION = 5  # Duration of audio clips in seconds\n",
        "N_MELS = 128  # Number of Mel frequency bins"
      ],
      "metadata": {
        "id": "gDuzsvy4fAu2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = {}\n",
        "\n",
        "with open(LABEL_FILE_PATH, 'r') as label_file:\n",
        "    lines = label_file.readlines()\n",
        "\n",
        "for line in lines:\n",
        "    parts = line.strip().split()\n",
        "    file_name = parts[1]\n",
        "    label = 1 if parts[-1] == \"bonafide\" else 0\n",
        "    labels[file_name] = label\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "max_time_steps = 109  # Define the maximum time steps for your model\n",
        "\n",
        "for file_name, label in labels.items():\n",
        "    file_path = os.path.join(DATASET_PATH, file_name + \".flac\")\n",
        "\n",
        "    # Load audio file using librosa\n",
        "    audio, _ = librosa.load(file_path, sr=SAMPLE_RATE, duration=DURATION)\n",
        "\n",
        "    # Extract Mel spectrogram using librosa\n",
        "    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=SAMPLE_RATE, n_mels=N_MELS)\n",
        "    mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
        "\n",
        "    # Ensure all spectrograms have the same width (time steps)\n",
        "    if mel_spectrogram.shape[1] < max_time_steps:\n",
        "        mel_spectrogram = np.pad(mel_spectrogram, ((0, 0), (0, max_time_steps - mel_spectrogram.shape[1])), mode='constant')\n",
        "    else:\n",
        "        mel_spectrogram = mel_spectrogram[:, :max_time_steps]\n",
        "\n",
        "    X.append(mel_spectrogram)\n",
        "    y.append(label)"
      ],
      "metadata": {
        "id": "9PUgLj2BfWwj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "X,y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFq67FLEmXid",
        "outputId": "4dd365d0-bbc0-4575-b523-e7fc87f3ff6b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[-78.88214 , -80.      , -80.      , ...,   0.      ,\n",
              "            0.      ,   0.      ],\n",
              "         [-71.71661 , -77.353325, -80.      , ...,   0.      ,\n",
              "            0.      ,   0.      ],\n",
              "         [-57.14656 , -59.50205 , -57.573334, ...,   0.      ,\n",
              "            0.      ,   0.      ],\n",
              "         ...,\n",
              "         [-69.18776 , -63.819817, -67.85419 , ...,   0.      ,\n",
              "            0.      ,   0.      ],\n",
              "         [-70.22391 , -64.85324 , -68.70045 , ...,   0.      ,\n",
              "            0.      ,   0.      ],\n",
              "         [-72.25124 , -66.18086 , -68.856   , ...,   0.      ,\n",
              "            0.      ,   0.      ]],\n",
              " \n",
              "        [[-72.254776, -78.77455 , -80.      , ..., -80.      ,\n",
              "          -80.      , -80.      ],\n",
              "         [-69.887405, -76.79361 , -80.      , ..., -80.      ,\n",
              "          -80.      , -80.      ],\n",
              "         [-57.00554 , -52.203255, -48.832603, ..., -73.142075,\n",
              "          -71.93824 , -75.95265 ],\n",
              "         ...,\n",
              "         [-80.      , -68.084435, -64.63213 , ..., -47.64021 ,\n",
              "          -42.370796, -41.053646],\n",
              "         [-80.      , -71.97934 , -66.842735, ..., -47.473797,\n",
              "          -43.83806 , -44.393692],\n",
              "         [-80.      , -67.650856, -64.05495 , ..., -48.77234 ,\n",
              "          -44.32927 , -45.339767]],\n",
              " \n",
              "        [[-53.237053, -60.58359 , -78.20593 , ...,   0.      ,\n",
              "            0.      ,   0.      ],\n",
              "         [-49.659805, -56.12284 , -61.2259  , ...,   0.      ,\n",
              "            0.      ,   0.      ],\n",
              "         [-34.84016 , -30.983528, -29.60375 , ...,   0.      ,\n",
              "            0.      ,   0.      ],\n",
              "         ...,\n",
              "         [-61.357548, -60.092934, -68.16925 , ...,   0.      ,\n",
              "            0.      ,   0.      ],\n",
              "         [-62.444016, -61.355934, -69.548904, ...,   0.      ,\n",
              "            0.      ,   0.      ],\n",
              "         [-72.648056, -74.72666 , -80.      , ...,   0.      ,\n",
              "            0.      ,   0.      ]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[-70.837746, -77.34403 , -80.      , ..., -80.      ,\n",
              "          -80.      , -80.      ],\n",
              "         [-68.34426 , -74.38833 , -80.      , ..., -80.      ,\n",
              "          -80.      , -80.      ],\n",
              "         [-61.59832 , -56.580044, -56.023483, ..., -53.42282 ,\n",
              "          -59.473015, -58.80858 ],\n",
              "         ...,\n",
              "         [-80.      , -80.      , -80.      , ..., -49.62439 ,\n",
              "          -52.244774, -54.32705 ],\n",
              "         [-80.      , -80.      , -80.      , ..., -52.743706,\n",
              "          -54.695366, -57.48861 ],\n",
              "         [-80.      , -80.      , -80.      , ..., -63.223595,\n",
              "          -64.968285, -69.97818 ]],\n",
              " \n",
              "        [[-79.72073 , -80.      , -80.      , ..., -80.      ,\n",
              "          -80.      , -80.      ],\n",
              "         [-76.66609 , -80.      , -80.      , ..., -80.      ,\n",
              "          -80.      , -80.      ],\n",
              "         [-65.12605 , -62.71192 , -64.38991 , ..., -57.916336,\n",
              "          -54.674156, -57.635284],\n",
              "         ...,\n",
              "         [-80.      , -80.      , -80.      , ..., -79.89459 ,\n",
              "          -69.113205, -60.563526],\n",
              "         [-80.      , -80.      , -80.      , ..., -79.91475 ,\n",
              "          -70.164154, -62.858734],\n",
              "         [-80.      , -80.      , -80.      , ..., -77.96855 ,\n",
              "          -68.23069 , -61.9974  ]],\n",
              " \n",
              "        [[-80.      , -80.      , -80.      , ..., -80.      ,\n",
              "          -80.      , -80.      ],\n",
              "         [-79.42154 , -80.      , -80.      , ..., -80.      ,\n",
              "          -80.      , -80.      ],\n",
              "         [-65.12895 , -66.69223 , -73.53928 , ..., -42.104374,\n",
              "          -46.978424, -57.833405],\n",
              "         ...,\n",
              "         [-80.      , -80.      , -80.      , ..., -80.      ,\n",
              "          -80.      , -80.      ],\n",
              "         [-80.      , -80.      , -80.      , ..., -80.      ,\n",
              "          -80.      , -80.      ],\n",
              "         [-80.      , -80.      , -80.      , ..., -80.      ,\n",
              "          -80.      , -80.      ]]], dtype=float32),\n",
              " array([0, 0, 0, ..., 0, 1, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_encoded = to_categorical(y, NUM_CLASSES)"
      ],
      "metadata": {
        "id": "5i9NE26Lmgbg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dense\n",
        "\n",
        "# Define Transformer model architecture\n",
        "input_shape = (N_MELS, X_train.shape[2])  # Input shape for Transformer (time steps, features)\n",
        "num_classes = NUM_CLASSES\n",
        "\n",
        "# Input layer\n",
        "inputs = Input(shape=input_shape)\n",
        "\n",
        "# Positional encoding\n",
        "position_embeddings = Embedding(input_shape[0], input_shape[1])(tf.range(input_shape[0]))\n",
        "x = inputs + position_embeddings\n",
        "\n",
        "# Transformer layers\n",
        "num_heads = 8\n",
        "ff_dim = 64\n",
        "num_layers = 4\n",
        "embedding_dim = 32\n",
        "\n",
        "for _ in range(num_layers):\n",
        "    # Multi-head self-attention\n",
        "    x = LayerNormalization()(x)\n",
        "    attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim)(x, x)\n",
        "    x = x + attention_output\n",
        "\n",
        "  # Feed-forward layer\n",
        "    x = LayerNormalization()(x)\n",
        "    x_ff = Dense(units=ff_dim, activation='relu')(x)\n",
        "    x_ff = Dropout(0.1)(x_ff)\n",
        "    x_ff = Dense(units=109, activation='relu')(x_ff)\n",
        "    x_ff = Dropout(0.1)(x_ff)\n",
        "    x = x + x_ff\n",
        "\n",
        "# Global Average Pooling\n",
        "x = GlobalAveragePooling1D()(x)\n",
        "\n",
        "# Output layer\n",
        "outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Define the model\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sQaR8yLU2qlp",
        "outputId": "13a0b90e-e64a-4c2d-c514-144e7a0ca03e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m109\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m109\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m109\u001b[0m)       │            \u001b[38;5;34m218\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m109\u001b[0m)       │        \u001b[38;5;34m112,493\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m109\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ multi_head_attention[\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m109\u001b[0m)       │            \u001b[38;5;34m218\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m7,040\u001b[0m │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m109\u001b[0m)       │          \u001b[38;5;34m7,085\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m109\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m109\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n",
              "│                           │                        │                │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m109\u001b[0m)       │            \u001b[38;5;34m218\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m109\u001b[0m)       │        \u001b[38;5;34m112,493\u001b[0m │ layer_normalization_2… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m109\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_2… │\n",
              "│                           │                        │                │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m109\u001b[0m)       │            \u001b[38;5;34m218\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m7,040\u001b[0m │ layer_normalization_3… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m109\u001b[0m)       │          \u001b[38;5;34m7,085\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m109\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m109\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_3… │\n",
              "│                           │                        │                │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m109\u001b[0m)       │            \u001b[38;5;34m218\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m109\u001b[0m)       │        \u001b[38;5;34m112,493\u001b[0m │ layer_normalization_4… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_4… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m109\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_4… │\n",
              "│                           │                        │                │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m109\u001b[0m)       │            \u001b[38;5;34m218\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m7,040\u001b[0m │ layer_normalization_5… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m109\u001b[0m)       │          \u001b[38;5;34m7,085\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m109\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_6 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m109\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_5… │\n",
              "│                           │                        │                │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m109\u001b[0m)       │            \u001b[38;5;34m218\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_3    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m109\u001b[0m)       │        \u001b[38;5;34m112,493\u001b[0m │ layer_normalization_6… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_6… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_7 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m109\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_6… │\n",
              "│                           │                        │                │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m109\u001b[0m)       │            \u001b[38;5;34m218\u001b[0m │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m7,040\u001b[0m │ layer_normalization_7… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m109\u001b[0m)       │          \u001b[38;5;34m7,085\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m109\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_8 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m109\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_7… │\n",
              "│                           │                        │                │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling1d  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ add_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m220\u001b[0m │ global_average_poolin… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">218</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">112,493</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ multi_head_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">218</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">7,040</span> │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">7,085</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n",
              "│                           │                        │                │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">218</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">112,493</span> │ layer_normalization_2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_2… │\n",
              "│                           │                        │                │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">218</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">7,040</span> │ layer_normalization_3… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">7,085</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_3… │\n",
              "│                           │                        │                │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">218</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">112,493</span> │ layer_normalization_4… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_4… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_4… │\n",
              "│                           │                        │                │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">218</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">7,040</span> │ layer_normalization_5… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">7,085</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_5… │\n",
              "│                           │                        │                │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">218</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_3    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">112,493</span> │ layer_normalization_6… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_6… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_6… │\n",
              "│                           │                        │                │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">218</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">7,040</span> │ layer_normalization_7… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">7,085</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_7… │\n",
              "│                           │                        │                │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling1d  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">220</span> │ global_average_poolin… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m508,436\u001b[0m (1.94 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">508,436</span> (1.94 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m508,436\u001b[0m (1.94 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">508,436</span> (1.94 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, batch_size=32, epochs=10, validation_split=0.2)\n",
        "# Print the number of samples for training and testing\n",
        "print(\"Number of training samples:\", X_train.shape[0])\n",
        "print(\"Number of testing samples:\", X_test.shape[0])\n",
        "\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "# Print the test loss and accuracy\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "# Predict using the trained model\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Compute confusion matrix\n",
        "conf_matrix = confusion_matrix(np.argmax(y_test, axis=1), y_pred_classes)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CI_9XhsnZ4Dw",
        "outputId": "68bd7031-519a-4a61-c288-b9fbbd36e22b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1425/1425\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9421 - loss: 0.1281 - val_accuracy: 0.9214 - val_loss: 0.1794\n",
            "Epoch 2/10\n",
            "\u001b[1m1425/1425\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9429 - loss: 0.1268 - val_accuracy: 0.9169 - val_loss: 0.1787\n",
            "Epoch 3/10\n",
            "\u001b[1m1425/1425\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9395 - loss: 0.1302 - val_accuracy: 0.9160 - val_loss: 0.1758\n",
            "Epoch 4/10\n",
            "\u001b[1m1425/1425\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9433 - loss: 0.1262 - val_accuracy: 0.9192 - val_loss: 0.1732\n",
            "Epoch 5/10\n",
            "\u001b[1m1425/1425\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9442 - loss: 0.1223 - val_accuracy: 0.9216 - val_loss: 0.1742\n",
            "Epoch 6/10\n",
            "\u001b[1m1425/1425\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9443 - loss: 0.1241 - val_accuracy: 0.9187 - val_loss: 0.1738\n",
            "Epoch 7/10\n",
            "\u001b[1m1425/1425\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9464 - loss: 0.1199 - val_accuracy: 0.9210 - val_loss: 0.1751\n",
            "Epoch 8/10\n",
            "\u001b[1m1425/1425\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9462 - loss: 0.1206 - val_accuracy: 0.9203 - val_loss: 0.1701\n",
            "Epoch 9/10\n",
            "\u001b[1m1425/1425\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9468 - loss: 0.1195 - val_accuracy: 0.9218 - val_loss: 0.1772\n",
            "Epoch 10/10\n",
            "\u001b[1m1425/1425\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9456 - loss: 0.1216 - val_accuracy: 0.9222 - val_loss: 0.1735\n",
            "Number of training samples: 56989\n",
            "Number of testing samples: 14248\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9227 - loss: 0.1710\n",
            "Test Loss: 0.17222997546195984\n",
            "Test Accuracy: 0.9222347140312195\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAApoAAAIjCAYAAACjybtCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABOwUlEQVR4nO3deVhV5d7G8XsjskEUUFSQVDRnyxxLcfaNpNLKtFOmJZpDGo44ZaWpWXQ0Z0szM620zFNaDqkcTa3ECSOH1LQcKgVHRFABYb1/9LJfd2iB8gi6v59z7es6e61nr/Vbu0PX79zPWs+2WZZlCQAAAMhjbvldAAAAAG5PNJoAAAAwgkYTAAAARtBoAgAAwAgaTQAAABhBowkAAAAjaDQBAABgBI0mAAAAjKDRBAAAgBE0mgD+1oEDB9S6dWv5+vrKZrNp6dKleXr8w4cPy2azad68eXl63FtZy5Yt1bJly/wuAwBuGI0mcAv45Zdf9Pzzz+vOO++Up6enfHx81KRJE02dOlUXL140eu7w8HDt2rVLr7/+uj766CM1aNDA6Plupq5du8pms8nHx+eq3+OBAwdks9lks9n01ltv5fr4x44d0+jRoxUXF5cH1QLArcc9vwsA8PdWrFihf/3rX7Lb7erSpYvuvvtupaWl6bvvvtPQoUO1Z88ezZ4928i5L168qJiYGL388svq27evkXMEBwfr4sWLKly4sJHj/xN3d3dduHBBy5Yt05NPPum0b8GCBfL09NSlS5eu69jHjh3TmDFjVKFCBdWpUyfHn1uzZs11nQ8AChoaTaAAO3TokDp27Kjg4GCtW7dOZcqUceyLiIjQwYMHtWLFCmPnP3nypCTJz8/P2DlsNps8PT2NHf+f2O12NWnSRJ988km2RnPhwoVq06aNPv/885tSy4ULF1SkSBF5eHjclPMBgGlMnQMF2Pjx45WcnKz333/fqcnMUrlyZQ0YMMDx/vLly3rttddUqVIl2e12VahQQS+99JJSU1OdPlehQgW1bdtW3333ne677z55enrqzjvv1IcffugYM3r0aAUHB0uShg4dKpvNpgoVKkj6c8o5679fafTo0bLZbE7boqOj1bRpU/n5+alo0aKqVq2aXnrpJcf+a92juW7dOjVr1kze3t7y8/PTY489pr179171fAcPHlTXrl3l5+cnX19fdevWTRcuXLj2F/sXnTp10tdff63ExETHtm3btunAgQPq1KlTtvFnzpzRkCFDVKtWLRUtWlQ+Pj566KGH9OOPPzrGrF+/Xvfee68kqVu3bo4p+KzrbNmype6++27FxsaqefPmKlKkiON7+es9muHh4fL09Mx2/WFhYSpevLiOHTuW42sFgJuJRhMowJYtW6Y777xTjRs3ztH4Hj16aNSoUapXr54mT56sFi1aKCoqSh07dsw29uDBg3riiSf0wAMPaOLEiSpevLi6du2qPXv2SJLat2+vyZMnS5KefvppffTRR5oyZUqu6t+zZ4/atm2r1NRUjR07VhMnTtSjjz6q77///m8/99///ldhYWE6ceKERo8ercjISG3atElNmjTR4cOHs41/8skndf78eUVFRenJJ5/UvHnzNGbMmBzX2b59e9lsNn3xxReObQsXLlT16tVVr169bON//fVXLV26VG3bttWkSZM0dOhQ7dq1Sy1atHA0fTVq1NDYsWMlSb169dJHH32kjz76SM2bN3cc5/Tp03rooYdUp04dTZkyRa1atbpqfVOnTlWpUqUUHh6ujIwMSdK7776rNWvWaPr06QoKCsrxtQLATWUBKJDOnTtnSbIee+yxHI2Pi4uzJFk9evRw2j5kyBBLkrVu3TrHtuDgYEuStXHjRse2EydOWHa73Ro8eLBj26FDhyxJ1oQJE5yOGR4ebgUHB2er4dVXX7Wu/NfK5MmTLUnWyZMnr1l31jk++OADx7Y6depYpUuXtk6fPu3Y9uOPP1pubm5Wly5dsp3vueeeczrm448/bvn7+1/znFdeh7e3t2VZlvXEE09Y999/v2VZlpWRkWEFBgZaY8aMuep3cOnSJSsjIyPbddjtdmvs2LGObdu2bct2bVlatGhhSbJmzZp11X0tWrRw2rZ69WpLkjVu3Djr119/tYoWLWq1a9fuH68RAPITiSZQQCUlJUmSihUrlqPxK1eulCRFRkY6bR88eLAkZbuXs2bNmmrWrJnjfalSpVStWjX9+uuv113zX2Xd2/nll18qMzMzR585fvy44uLi1LVrV5UoUcKx/Z577tEDDzzguM4r9e7d2+l9s2bNdPr0acd3mBOdOnXS+vXrFR8fr3Xr1ik+Pv6q0+bSn/d1urn9+a/PjIwMnT592nFbwI4dO3J8Trvdrm7duuVobOvWrfX8889r7Nixat++vTw9PfXuu+/m+FwAkB9oNIECysfHR5J0/vz5HI0/cuSI3NzcVLlyZaftgYGB8vPz05EjR5y2ly9fPtsxihcvrrNnz15nxdk99dRTatKkiXr06KGAgAB17NhRn3322d82nVl1VqtWLdu+GjVq6NSpU0pJSXHa/tdrKV68uCTl6loefvhhFStWTIsWLdKCBQt07733Zvsus2RmZmry5MmqUqWK7Ha7SpYsqVKlSmnnzp06d+5cjs95xx135OrBn7feekslSpRQXFycpk2bptKlS+f4swCQH2g0gQLKx8dHQUFB2r17d64+99eHca6lUKFCV91uWdZ1nyPr/sEsXl5e2rhxo/773//q2Wef1c6dO/XUU0/pgQceyDb2RtzItWSx2+1q37695s+fryVLllwzzZSkN954Q5GRkWrevLk+/vhjrV69WtHR0brrrrtynNxKf34/ufHDDz/oxIkTkqRdu3bl6rMAkB9oNIECrG3btvrll18UExPzj2ODg4OVmZmpAwcOOG1PSEhQYmKi4wnyvFC8eHGnJ7Sz/DU1lSQ3Nzfdf//9mjRpkn766Se9/vrrWrdunb755purHjurzv3792fbt2/fPpUsWVLe3t43dgHX0KlTJ/3www86f/78VR+gyvKf//xHrVq10vvvv6+OHTuqdevWCg0Nzfad5LTpz4mUlBR169ZNNWvWVK9evTR+/Hht27Ytz44PACbQaAIF2LBhw+Tt7a0ePXooISEh2/5ffvlFU6dOlfTn1K+kbE+GT5o0SZLUpk2bPKurUqVKOnfunHbu3OnYdvz4cS1ZssRp3JkzZ7J9Nmvh8r8uuZSlTJkyqlOnjubPn+/UuO3evVtr1qxxXKcJrVq10muvvaYZM2YoMDDwmuMKFSqULS1dvHix/vjjD6dtWQ3x1Zry3Bo+fLiOHj2q+fPna9KkSapQoYLCw8Ov+T0CQEHAgu1AAVapUiUtXLhQTz31lGrUqOH0y0CbNm3S4sWL1bVrV0lS7dq1FR4ertmzZysxMVEtWrTQ1q1bNX/+fLVr1+6aS+dcj44dO2r48OF6/PHH1b9/f124cEEzZ85U1apVnR6GGTt2rDZu3Kg2bdooODhYJ06c0DvvvKOyZcuqadOm1zz+hAkT9NBDDykkJETdu3fXxYsXNX36dPn6+mr06NF5dh1/5ebmpldeeeUfx7Vt21Zjx45Vt27d1LhxY+3atUsLFizQnXfe6TSuUqVK8vPz06xZs1SsWDF5e3urYcOGqlixYq7qWrdund555x29+uqrjuWWPvjgA7Vs2VIjR47U+PHjc3U8ALhZSDSBAu7RRx/Vzp079cQTT+jLL79URESEXnzxRR0+fFgTJ07UtGnTHGPnzJmjMWPGaNu2bRo4cKDWrVunESNG6NNPP83Tmvz9/bVkyRIVKVJEw4YN0/z58xUVFaVHHnkkW+3ly5fX3LlzFRERobffflvNmzfXunXr5Ovre83jh4aGatWqVfL399eoUaP01ltvqVGjRvr+++9z3aSZ8NJLL2nw4MFavXq1BgwYoB07dmjFihUqV66c07jChQtr/vz5KlSokHr37q2nn35aGzZsyNW5zp8/r+eee05169bVyy+/7NjerFkzDRgwQBMnTtTmzZvz5LoAIK/ZrNzcLQ8AAADkEIkmAAAAjKDRBAAAgBE0mgAAADCCRhMAAABG0GgCAADACBpNAAAAGEGjCQAAACNuy18G8qrbN79LAGDI2W0z8rsEAIZ45mNXYrJ3uPiD6/57i0QTAAAARtyWiSYAAECu2MjeTKDRBAAAsNnyu4LbEu07AAAAjCDRBAAAYOrcCL5VAAAAGEGiCQAAwD2aRpBoAgAAwAgSTQAAAO7RNIJvFQAAAEbQaAIAANhs5l65tHHjRj3yyCMKCgqSzWbT0qVLHfvS09M1fPhw1apVS97e3goKClKXLl107Ngxp2OcOXNGnTt3lo+Pj/z8/NS9e3clJyc7jdm5c6eaNWsmT09PlStXTuPHj89Wy+LFi1W9enV5enqqVq1aWrlyZa6uhUYTAADA5mbulUspKSmqXbu23n777Wz7Lly4oB07dmjkyJHasWOHvvjiC+3fv1+PPvqo07jOnTtrz549io6O1vLly7Vx40b16tXLsT8pKUmtW7dWcHCwYmNjNWHCBI0ePVqzZ892jNm0aZOefvppde/eXT/88IPatWundu3aaffu3Tn/Wi3LsnL9DRRwXnX75ncJAAw5u21GfpcAwBDPfHxyxKvRcGPHvrj539f9WZvNpiVLlqhdu3bXHLNt2zbdd999OnLkiMqXL6+9e/eqZs2a2rZtmxo0aCBJWrVqlR5++GH9/vvvCgoK0syZM/Xyyy8rPj5eHh4ekqQXX3xRS5cu1b59+yRJTz31lFJSUrR8+XLHuRo1aqQ6depo1qxZOaqfRBMAAMDg1HlqaqqSkpKcXqmpqXlW+rlz52Sz2eTn5ydJiomJkZ+fn6PJlKTQ0FC5ublpy5YtjjHNmzd3NJmSFBYWpv379+vs2bOOMaGhoU7nCgsLU0xMTI5ro9EEAAAwKCoqSr6+vk6vqKioPDn2pUuXNHz4cD399NPy8fGRJMXHx6t06dJO49zd3VWiRAnFx8c7xgQEBDiNyXr/T2Oy9ucEyxsBAAAYXN5oxIgRioyMdNpmt9tv+Ljp6el68sknZVmWZs6cecPHM4FGEwAAwCC73Z4njeWVsprMI0eOaN26dY40U5ICAwN14sQJp/GXL1/WmTNnFBgY6BiTkJDgNCbr/T+NydqfE0ydAwAAFKDljf5JVpN54MAB/fe//5W/v7/T/pCQECUmJio2Ntaxbd26dcrMzFTDhg0dYzZu3Kj09HTHmOjoaFWrVk3Fixd3jFm7dq3TsaOjoxUSEpLjWmk0AQAACpDk5GTFxcUpLi5OknTo0CHFxcXp6NGjSk9P1xNPPKHt27drwYIFysjIUHx8vOLj45WWliZJqlGjhh588EH17NlTW7du1ffff6++ffuqY8eOCgoKkiR16tRJHh4e6t69u/bs2aNFixZp6tSpTlP8AwYM0KpVqzRx4kTt27dPo0eP1vbt29W3b85X92F5IwC3FJY3Am5f+bq8UdORxo598bvXcjV+/fr1atWqVbbt4eHhGj16tCpWrHjVz33zzTdq2bKlpD8XbO/bt6+WLVsmNzc3dejQQdOmTVPRokUd43fu3KmIiAht27ZNJUuWVL9+/TR8uPMyT4sXL9Yrr7yiw4cPq0qVKho/frwefvjhHF8LjSaAWwqNJnD7ytdGs9koY8e++O1YY8cu6Jg6BwAAgBE8dQ4AAGBweSNXxrcKAAAAI0g0AQAASDSN4FsFAACAESSaAAAAbnm/sDpINAEAAGAIiSYAAAD3aBpBowkAAGDgN8nB1DkAAAAMIdEEAABg6twIvlUAAAAYQaIJAADAPZpGkGgCAADACBJNAAAA7tE0gm8VAAAARpBoAgAAcI+mETSaAAAATJ0bwbcKAAAAI0g0AQAAmDo3gkQTAAAARpBoAgAAcI+mEXyrAAAAMIJEEwAAgHs0jSDRBAAAgBEkmgAAANyjaQSNJgAAAI2mEXyrAAAAMIJEEwAAgIeBjCDRBAAAgBEkmgAAANyjaQTfKgAAAIwg0QQAAOAeTSNINAEAAGAEiSYAAAD3aBpBowkAAMDUuRG07wAAADCCRBMAALg8G4mmESSaAAAAMIJEEwAAuDwSTTNINAEAAGAEiSYAAACBphEkmgAAADCCRBMAALg87tE0g0YTAAC4PBpNM5g6BwAAgBEkmgAAwOWRaJpBogkAAAAjSDQBAIDLI9E0g0QTAAAARpBoAgAAEGgaQaIJAAAAI0g0AQCAy+MeTTNINAEAAGAEiSYAAHB5JJpm0GgCAACXR6NpBlPnAAAAMIJEEwAAuDwSTTNINAEAAGAEiSYAAACBphEkmgAAADCCRBMAALg87tE0g0QTAAAARpBoAgAAl0eiaQaNJgAAcHk0mmYwdQ4AAAAjaDQBAABsBl+5tHHjRj3yyCMKCgqSzWbT0qVLnfZblqVRo0apTJky8vLyUmhoqA4cOOA05syZM+rcubN8fHzk5+en7t27Kzk52WnMzp071axZM3l6eqpcuXIaP358tloWL16s6tWry9PTU7Vq1dLKlStzdS00mgAAAAVISkqKateurbfffvuq+8ePH69p06Zp1qxZ2rJli7y9vRUWFqZLly45xnTu3Fl79uxRdHS0li9fro0bN6pXr16O/UlJSWrdurWCg4MVGxurCRMmaPTo0Zo9e7ZjzKZNm/T000+re/fu+uGHH9SuXTu1a9dOu3fvzvG12CzLsq7jOyjQvOr2ze8SABhydtuM/C4BgCGe+fjkSECPxcaOnTDnX9f9WZvNpiVLlqhdu3aS/kwzg4KCNHjwYA0ZMkSSdO7cOQUEBGjevHnq2LGj9u7dq5o1a2rbtm1q0KCBJGnVqlV6+OGH9fvvvysoKEgzZ87Uyy+/rPj4eHl4eEiSXnzxRS1dulT79u2TJD311FNKSUnR8uXLHfU0atRIderU0axZs3JUP4kmAACAQampqUpKSnJ6paamXtexDh06pPj4eIWGhjq2+fr6qmHDhoqJiZEkxcTEyM/Pz9FkSlJoaKjc3Ny0ZcsWx5jmzZs7mkxJCgsL0/79+3X27FnHmCvPkzUm6zw5QaMJAABcns1mM/aKioqSr6+v0ysqKuq66oyPj5ckBQQEOG0PCAhw7IuPj1fp0qWd9ru7u6tEiRJOY652jCvPca0xWftzguWNAAAADBoxYoQiIyOdttnt9nyq5uai0QQAAC7P5Dqadrs9zxrLwMBASVJCQoLKlCnj2J6QkKA6deo4xpw4ccLpc5cvX9aZM2ccnw8MDFRCQoLTmKz3/zQma39OMHUOAABcnsmp87xUsWJFBQYGau3atY5tSUlJ2rJli0JCQiRJISEhSkxMVGxsrGPMunXrlJmZqYYNGzrGbNy4Uenp6Y4x0dHRqlatmooXL+4Yc+V5ssZknScnaDQBAAAKkOTkZMXFxSkuLk7Snw8AxcXF6ejRo7LZbBo4cKDGjRunr776Srt27VKXLl0UFBTkeDK9Ro0aevDBB9WzZ09t3bpV33//vfr27auOHTsqKChIktSpUyd5eHioe/fu2rNnjxYtWqSpU6c6TfEPGDBAq1at0sSJE7Vv3z6NHj1a27dvV9++OV/dh6lzAACAAvQLlNu3b1erVq0c77Oav/DwcM2bN0/Dhg1TSkqKevXqpcTERDVt2lSrVq2Sp6en4zMLFixQ3759df/998vNzU0dOnTQtGnTHPt9fX21Zs0aRUREqH79+ipZsqRGjRrltNZm48aNtXDhQr3yyit66aWXVKVKFS1dulR33313jq+FdTQB3FJYRxO4feXnOppBvb8wduxjs9obO3ZBR6IJAABcnsmHgVwZ92gCAADACBJNAADg8kg0zSDRBAAAgBEkmgAAwOWRaJpBowkAAECfaQRT5wAAADCCRBMAALg8ps7NINEEAACAESSaAADA5ZFomkGiCQAAACNINHHTNalXSYO6hKpezfIqU8pXTw6arWXrd0qS3N3dNPqFRxTW9C5VLOuvpORLWrdln0ZO+0rHT55zHGPxlOdVu+odKlWimM4mXdA3W/brlWlfOo3p8EBdDe0epirlS+tUYrJmfbpBkz9c69gfWNJHb0a2V72a5VWpXEm988kGDX3r85v3RQAu6LNPF+qzRZ/o2B9/SJIqVa6i5/u8oKbNWkiSTp08qUkTx2vzpk1KuZCiChUqqmev3gptHeY4xuHDhzT5rfGK+2GH0tPTVaVqNUX0G6D7GjbKl2vC7YFE0wwSTdx03l527fr5Dw2MWpRtXxFPD9WpUU5vvve1Qp7+tzoOfk9VgwO0eMrzTuM2bvtZzwyfq9qPj1WnoXN0Z7mSWjihu2N/6yY19cHrXTXnP9+p/r9e14A3FqnfM/+j3k81d4zxKOyuU2fP6805q7Tz5z/MXTAAh9IBgRowaIg+WfyFFn72ue5r2EgD+kbo4MEDkqSXXxquw4cOaeqMmfp8yTLdH/qAhg4eqL17f3Ico98LvZWRkaH35s7XJ4u/ULVq1dUvordOnTyZX5cF4BpINHHTrfn+J635/qer7ktKvqS2fWY4bRv05mf6bsEwlQssrt/iz0qSpi/4xrH/6PGzeuuDaH02qafc3d10+XKmOrW5T8vW/6g5//lOknT4j9OaMHeNBnd9QLMWbfy/z53RkAl/Jpjhj4Xk+XUCyK5lq/9xet9vwCB99ukn2vljnCpXrqIff/hBL496VbXuuUeS1Kv3C/r4w/nau2ePatSoqbNnz+jokcMa89rrqlqtuiRpQORgLfp0oQ4ePKCSpUrd9GvC7YFE04x8bTRPnTqluXPnKiYmRvHx8ZKkwMBANW7cWF27dlUp/oUBST7FvJSZmanE8xevur+4TxF1fKiBNv94SJcvZ0qS7B7uunAxzWncxdQ0lQ0srvJlSujo8TPG6wbw9zIyMrRm9SpdvHhBtWvXlSTVrltXq1d9rebNW6qYj49Wr/paqWmpanDvfZIkP7/iqlCxopZ9uVTVa9SUh4eH/vPZIpXw91fNmnfl5+XgVkefaUS+NZrbtm1TWFiYihQpotDQUFWtWlWSlJCQoGnTpunNN9/U6tWr1aBBg789TmpqqlJTU522WZkZsrkVMlY7bh67h7vG9X9Mn62K1fmUS077xvV/TL07Npe3l11bdh5S+/6zHPuiN+3V+CHt9dGyqtqw7YAqlSulAc/cL0kqU8qXRhPIRwd+3q9nO3VUWlqqihQposnT3lalypUlSRMmTtGwwYPUvElDubu7y9PTU5OnzlD54GBJf6ZOs+fM08D+L6jxffXk5uamEiVK6J1358jH1zc/LwvAVeRbo9mvXz/961//0qxZs7LF1ZZlqXfv3urXr59iYmL+9jhRUVEaM2aM07ZCAfeqcJn78rxm3Fzu7m76eHx32Ww29X8j+/2ckz/8r+YtjVH5MiX08vMPac5rzzqazblffK87y5bUF1N7q7B7ISWlXNLbC9drZJ82yszMvNmXAuAKFSpU1GefL1Vy8nlFr1mtkS8N1/vzPlalypX19vSpOn8+SbPfnyc/v+L6Zt1/NWzwQH3w4QJVqVpNlmXpjXFjVKKEvz74cIE8PT31xX8Wq39Eby1c9B+VKlU6vy8Ptyimzs3It0bzxx9/1Lx58676D9Zms2nQoEGqW7fuPx5nxIgRioyMdNpWutnwPKsT+cPd3U0L/t1d5csU10O9pmdLMyXpdGKKTiem6ODRE9p/KF4HV49Tw3sqasvOQ5KkV6Z9qVEzvlKgv49Onk1Wq4bVJEmH/jh9U68FgLPCHh6OhLLmXXdrz+5dWvDxh+r2XA99uvBjff7lclWuXEWSVK16de2I3a5PP1mgka+O1dYtm7Vxw3p9G7NNRYsWlSS9POoubY7ZpK+WLlX3nr3y7boAZJdvjWZgYKC2bt2q6tWrX3X/1q1bFRAQ8I/HsdvtstvtTtuYNr+1ZTWZlcqX0oO9punMuZR//Iyb25//h8WjsPP/pDMzLR37vyWPnnywvjb/+KtOnU3O+6IBXLfMzEylp6Xp0qU/78N2szkviOLmVkhWpiVJungxa4xzSGFzs8mymK3A9SPRNCPfGs0hQ4aoV69eio2N1f333+9oKhMSErR27Vq99957euutt/KrPBjk7eWhSuX+/0GvCnf4656qd+hs0gUdP3VOCyf0UN3q5dR+wCwVcrMpwL+YJOnMuQtKv5yhe+8OVv27grXph1+UeP6CKpYtpVdfaKNfjp50pJn+ft56PLSuNm4/IE8Pd3V5rJHah9ZV6x5TnWq5p+odf9ZUxK6SxYvqnqp3KO1yhvb9Gn+Tvg3AtUydPFFNmzVXYJkyupCSopUrlmv7tq2aOft9Vah4p8qXD9ZrY0Ypcshw+fn5ad26/2pzzPea/s67kqTaderIx8dHr7z0op7vEyG7p11f/Ocz/fH7H2rWvGX+XhyAbGyWZVn5dfJFixZp8uTJio2NVUZGhiSpUKFCql+/viIjI/Xkk09e13G96vbNyzKRx5rVr6I1cwZk2/7RV5s1btZK7V859qqfa91jqr6NPaC7KgfpraEdVKtqWXl7eSj+1Dmt2bRX/35vlSO99Pfz1udTe+uuykGy2aQtOw9p9Ixl2rb7iNMxL/4wI9t5jhw7reptXs2DK4UJZ7dl/2eGW8erI1/S1s2bdfLkCRUtVkxVq1ZTt+49FdK4iSTpyJHDmjppon74IVYXLlxQ+XLl1aXbc3rk0XaOY+zZvUvTp07RT3t26/Ll9GyLvuPW5ZmPa+FUHvK1sWMffOshY8cu6PK10cySnp6uU6dOSZJKliypwoUL39DxaDSB2xeNJnD7otG8/RSIBdsLFy6sMmXK5HcZAADARXGPphkFotEEAADIT/SZZvBb5wAAADCCRBMAALg8ps7NINEEAACAESSaAADA5RFomkGiCQAAACNINAEAgMvL+ilj5C0STQAAABhBogkAAFwe92iaQaMJAABcHssbmcHUOQAAAIwg0QQAAC6PQNMMEk0AAAAYQaIJAABcHvdomkGiCQAAACNINAEAgMsj0TSDRBMAAABGkGgCAACXR6BpBo0mAABweUydm8HUOQAAAIwg0QQAAC6PQNMMEk0AAAAYQaIJAABcHvdomkGiCQAAACNINAEAgMsj0DSDRBMAAABGkGgCAACXxz2aZpBoAgAAwAgSTQAA4PIINM2g0QQAAC6PqXMzmDoHAACAESSaAADA5RFomkGiCQAAACNINAEAgMvjHk0zSDQBAABgBIkmAABweQSaZpBoAgAAwAgSTQAA4PK4R9MMGk0AAODy6DPNYOocAAAARpBoAgAAl8fUuRkkmgAAADCCRBMAALg8Ek0zSDQBAAAKiIyMDI0cOVIVK1aUl5eXKlWqpNdee02WZTnGWJalUaNGqUyZMvLy8lJoaKgOHDjgdJwzZ86oc+fO8vHxkZ+fn7p3767k5GSnMTt37lSzZs3k6empcuXKafz48Xl+PTSaAADA5dls5l658e9//1szZ87UjBkztHfvXv373//W+PHjNX36dMeY8ePHa9q0aZo1a5a2bNkib29vhYWF6dKlS44xnTt31p49exQdHa3ly5dr48aN6tWrl2N/UlKSWrdureDgYMXGxmrChAkaPXq0Zs+efcPf5ZVs1pUt8m3Cq27f/C4BgCFnt83I7xIAGOKZjzf0tZj8vbFjbxjUJMdj27Ztq4CAAL3//vuObR06dJCXl5c+/vhjWZaloKAgDR48WEOGDJEknTt3TgEBAZo3b546duyovXv3qmbNmtq2bZsaNGggSVq1apUefvhh/f777woKCtLMmTP18ssvKz4+Xh4eHpKkF198UUuXLtW+ffvy7NpJNAEAgMuz2WzGXqmpqUpKSnJ6paamXrWOxo0ba+3atfr5558lST/++KO+++47PfTQQ5KkQ4cOKT4+XqGhoY7P+Pr6qmHDhoqJiZEkxcTEyM/Pz9FkSlJoaKjc3Ny0ZcsWx5jmzZs7mkxJCgsL0/79+3X27Nk8+15pNAEAgMszOXUeFRUlX19fp1dUVNRV63jxxRfVsWNHVa9eXYULF1bdunU1cOBAde7cWZIUHx8vSQoICHD6XEBAgGNffHy8Spcu7bTf3d1dJUqUcBpztWNceY68wFPnAAAABo0YMUKRkZFO2+x2+1XHfvbZZ1qwYIEWLlyou+66S3FxcRo4cKCCgoIUHh5+M8rNUzSaAADA5Zlc3shut1+zsfyroUOHOlJNSapVq5aOHDmiqKgohYeHKzAwUJKUkJCgMmXKOD6XkJCgOnXqSJICAwN14sQJp+NevnxZZ86ccXw+MDBQCQkJTmOy3meNyQtMnQMAABQQFy5ckJubc3tWqFAhZWZmSpIqVqyowMBArV271rE/KSlJW7ZsUUhIiCQpJCREiYmJio2NdYxZt26dMjMz1bBhQ8eYjRs3Kj093TEmOjpa1apVU/HixfPsemg0AQCAyysoyxs98sgjev3117VixQodPnxYS5Ys0aRJk/T444//X502DRw4UOPGjdNXX32lXbt2qUuXLgoKClK7du0kSTVq1NCDDz6onj17auvWrfr+++/Vt29fdezYUUFBQZKkTp06ycPDQ927d9eePXu0aNEiTZ06NdsU/41i6hwAAKCAmD59ukaOHKkXXnhBJ06cUFBQkJ5//nmNGjXKMWbYsGFKSUlRr169lJiYqKZNm2rVqlXy9PR0jFmwYIH69u2r+++/X25uburQoYOmTZvm2O/r66s1a9YoIiJC9evXV8mSJTVq1CintTbzAutoArilsI4mcPvKz3U0H5ix2dixo/s2Mnbsgo6pcwAAABjB1DkAAHB5Bh86d2k0mgAAwOWZXN7IlTF1DgAAACNINAEAgMtzI9A0gkQTAAAARpBoAgAAl8c9mmaQaAIAAMAIEk0AAODyCDTNINEEAACAESSaAADA5dlEpGkCjSYAAHB5LG9kBlPnAAAAMIJEEwAAuDyWNzKDRBMAAABGkGgCAACXR6BpBokmAAAAjCDRBAAALs+NSNOIXCea8+fP14oVKxzvhw0bJj8/PzVu3FhHjhzJ0+IAAABw68p1o/nGG2/Iy8tLkhQTE6O3335b48ePV8mSJTVo0KA8LxAAAMA0m83cy5Xleur8t99+U+XKlSVJS5cuVYcOHdSrVy81adJELVu2zOv6AAAAjGN5IzNynWgWLVpUp0+fliStWbNGDzzwgCTJ09NTFy9ezNvqAAAAcMvKdaL5wAMPqEePHqpbt65+/vlnPfzww5KkPXv2qEKFCnldHwAAgHEEmmbkOtF8++23FRISopMnT+rzzz+Xv7+/JCk2NlZPP/10nhcIAACAW1OuE00/Pz/NmDEj2/YxY8bkSUEAAAA3G8sbmZGjRnPnzp05PuA999xz3cUAAADg9pGjRrNOnTqy2WyyLOuq+7P22Ww2ZWRk5GmBAAAAppFnmpGjRvPQoUOm6wAAAMBtJkeNZnBwsOk6AAAA8g3raJqR66fOJemjjz5SkyZNFBQU5PjZySlTpujLL7/M0+IAAABuBjebuZcry3WjOXPmTEVGRurhhx9WYmKi455MPz8/TZkyJa/rAwAAwC0q143m9OnT9d577+nll19WoUKFHNsbNGigXbt25WlxAAAAN4PNZjP2cmW5bjQPHTqkunXrZttut9uVkpKSJ0UBAADg1pfrRrNixYqKi4vLtn3VqlWqUaNGXtQEAABwU9ls5l6uLNe/DBQZGamIiAhdunRJlmVp69at+uSTTxQVFaU5c+aYqBEAAAC3oFw3mj169JCXl5deeeUVXbhwQZ06dVJQUJCmTp2qjh07mqgRAADAKFe/l9KUXDeaktS5c2d17txZFy5cUHJyskqXLp3XdQEAAOAWd12NpiSdOHFC+/fvl/Tn/wsoVapUnhUFAABwM7n6epem5PphoPPnz+vZZ59VUFCQWrRooRYtWigoKEjPPPOMzp07Z6JGAAAAo1jeyIxcN5o9evTQli1btGLFCiUmJioxMVHLly/X9u3b9fzzz5uoEQAAALegXE+dL1++XKtXr1bTpk0d28LCwvTee+/pwQcfzNPiAAAAbgbXzh3NyXWi6e/vL19f32zbfX19Vbx48TwpCgAAALe+XDear7zyiiIjIxUfH+/YFh8fr6FDh2rkyJF5WhwAAMDN4GazGXu5shxNndetW9fpZtYDBw6ofPnyKl++vCTp6NGjstvtOnnyJPdpAgAAQFIOG8127doZLgMAACD/uHjwaEyOGs1XX33VdB0AAAC4zVz3gu0AAAC3C1df79KUXDeaGRkZmjx5sj777DMdPXpUaWlpTvvPnDmTZ8UBAADg1pXrp87HjBmjSZMm6amnntK5c+cUGRmp9u3by83NTaNHjzZQIgAAgFk2m7mXK8t1o7lgwQK99957Gjx4sNzd3fX0009rzpw5GjVqlDZv3myiRgAAAKNY3siMXDea8fHxqlWrliSpaNGijt83b9u2rVasWJG31QEAAOCWletGs2zZsjp+/LgkqVKlSlqzZo0kadu2bbLb7XlbHQAAwE3A1LkZuW40H3/8ca1du1aS1K9fP40cOVJVqlRRly5d9Nxzz+V5gQAAALg15fqp8zfffNPx35966ikFBwdr06ZNqlKlih555JE8LQ4AAOBmYHkjM3KdaP5Vo0aNFBkZqYYNG+qNN97Ii5oAAABwG7BZlmXlxYF+/PFH1atXTxkZGXlxuBty/lJmfpcAAAByqZjnDedf163fkr3Gjj398RrGjl3Q5d8/UQAAANzW+AlKAADg8rhH0wwaTQAA4PLc6DONyHGjGRkZ+bf7T548ecPFAAAA4PaR40bzhx9++McxzZs3v6FiAAAA8gOJphk5bjS/+eYbk3UAAADgNsM9mgAAwOXxMJAZLG8EAAAAI0g0AQCAy+MeTTNINAEAAGAEjSYAAHB5Npu5V2798ccfeuaZZ+Tv7y8vLy/VqlVL27dvd+y3LEujRo1SmTJl5OXlpdDQUB04cMDpGGfOnFHnzp3l4+MjPz8/de/eXcnJyU5jdu7cqWbNmsnT01PlypXT+PHjr+u7+zvX1Wh+++23euaZZxQSEqI//vhDkvTRRx/pu+++y9PiAAAAbgY3m83YKzfOnj2rJk2aqHDhwvr666/1008/aeLEiSpevLhjzPjx4zVt2jTNmjVLW7Zskbe3t8LCwnTp0iXHmM6dO2vPnj2Kjo7W8uXLtXHjRvXq1cuxPykpSa1bt1ZwcLBiY2M1YcIEjR49WrNnz77xL/MKuW40P//8c4WFhcnLy0s//PCDUlNTJUnnzp3TG2+8kafFAQAAuJJ///vfKleunD744APdd999qlixolq3bq1KlSpJ+jPNnDJlil555RU99thjuueee/Thhx/q2LFjWrp0qSRp7969WrVqlebMmaOGDRuqadOmmj59uj799FMdO3ZMkrRgwQKlpaVp7ty5uuuuu9SxY0f1799fkyZNytPryXWjOW7cOM2aNUvvvfeeChcu7NjepEkT7dixI0+LAwAAuBncDL5SU1OVlJTk9MoK6v7qq6++UoMGDfSvf/1LpUuXVt26dfXee+859h86dEjx8fEKDQ11bPP19VXDhg0VExMjSYqJiZGfn58aNGjgGBMaGio3Nzdt2bLFMaZ58+by8PBwjAkLC9P+/ft19uzZ6/sSryLXjeb+/fuv+gtAvr6+SkxMzIuaAAAAbhtRUVHy9fV1ekVFRV117K+//qqZM2eqSpUqWr16tfr06aP+/ftr/vz5kqT4+HhJUkBAgNPnAgICHPvi4+NVunRpp/3u7u4qUaKE05irHePKc+SFXC9vFBgYqIMHD6pChQpO27/77jvdeeedeVUXAADATWNyvfYRI0YoMjLSaZvdbr/q2MzMTDVo0MBxO2LdunW1e/duzZo1S+Hh4eaKNCTXiWbPnj01YMAAbdmyRTabTceOHdOCBQs0ZMgQ9enTx0SNAAAAtyy73S4fHx+n17UazTJlyqhmzZpO22rUqKGjR49K+jPwk6SEhASnMQkJCY59gYGBOnHihNP+y5cv68yZM05jrnaMK8+RF3LdaL744ovq1KmT7r//fiUnJ6t58+bq0aOHnn/+efXr1y/PCgMAALhZCspT502aNNH+/fudtv38888KDg6WJFWsWFGBgYFau3atY39SUpK2bNmikJAQSVJISIgSExMVGxvrGLNu3TplZmaqYcOGjjEbN25Uenq6Y0x0dLSqVavm9IT7jbJZlmVdzwfT0tJ08OBBJScnq2bNmipatGieFXWjzl/KzO8SAABALhXzzL/lvUeuOvDPg67Taw9WyfHYbdu2qXHjxhozZoyefPJJbd26VT179tTs2bPVuXNnSX8+mf7mm29q/vz5qlixokaOHKmdO3fqp59+kqenpyTpoYceUkJCgmbNmqX09HR169ZNDRo00MKFCyX9uVpQtWrV1Lp1aw0fPly7d+/Wc889p8mTJzstg3SjrrvRLMhoNAEAuPXkZ6M5arW5RnNsWM4bTUlavny5RowYoQMHDqhixYqKjIxUz549Hfsty9Krr76q2bNnKzExUU2bNtU777yjqlWrOsacOXNGffv21bJly+Tm5qYOHTpo2rRpTsHgzp07FRERoW3btqlkyZLq16+fhg8ffuMXfIVcN5qtWrWS7W9i4HXr1t1wUTeKRhMAgFtPfjaao9eYazRHt85do3k7yfVT53Xq1HF6n56erri4OO3evfuWfBoKAAAAZuS60Zw8efJVt48ePTrbb2gCAADcCnL70A5yJs8y6meeeUZz587Nq8MBAADgFpfrRPNaYmJiHE86AQAA3EoINM3IdaPZvn17p/eWZen48ePavn27Ro4cmWeFAQAA4NaW60bT19fX6b2bm5uqVaumsWPHqnXr1nlWGAAAwM3iRqJpRK4azYyMDHXr1k21atXK01XjAQAAcPvJ1cNAhQoVUuvWrZWYmGioHAAAgJvPZvA/rizXT53ffffd+vXXX03UAgAAkC/cbOZerizXjea4ceM0ZMgQLV++XMePH1dSUpLTCwAAAJBycY/m2LFjNXjwYD388MOSpEcffdTppygty5LNZlNGRkbeVwkAAGCQqyePpuT4t84LFSqk48ePa+/evX87rkWLFnlS2I3gt84BALj15OdvnY//5hdjxx7WqpKxYxd0OU40s/rRgtBIAgAA5CUbK7Ybkav/68A/BAAAAORUrtbRrFq16j82m2fOnLmhggAAAG427tE0I1eN5pgxY7L9MhAAAABwNblqNDt27KjSpUubqgUAACBfcHegGTluNLk/EwAA3K7c6HOMyPHDQDlcBQkAAACQlItEMzOTtSkBAMDtiYeBzMi/lVEBAABwW8vVw0AAAAC3I27RNINEEwAAAEaQaAIAAJfnJiJNE0g0AQAAYASJJgAAcHnco2kGjSYAAHB5LG9kBlPnAAAAMIJEEwAAuDx+gtIMEk0AAAAYQaIJAABcHoGmGSSaAAAAMIJEEwAAuDzu0TSDRBMAAABGkGgCAACXR6BpBo0mAABweUzxmsH3CgAAACNINAEAgMuzMXduBIkmAAAAjCDRBAAALo880wwSTQAAABhBogkAAFweC7abQaIJAAAAI0g0AQCAyyPPNINGEwAAuDxmzs1g6hwAAABGkGgCAACXx4LtZpBoAgAAwAgSTQAA4PJI3szgewUAAIARJJoAAMDlcY+mGSSaAAAAMIJEEwAAuDzyTDNINAEAAGAEiSYAAHB53KNpBo0mAABweUzxmsH3CgAAACNINAEAgMtj6twMEk0AAAAYQaIJAABcHnmmGSSaAAAAMIJEEwAAuDxu0TSDRBMAAABGkGgCAACX58ZdmkbQaAIAAJfH1LkZTJ0DAADACBpNAADg8mwG/3Mj3nzzTdlsNg0cONCx7dKlS4qIiJC/v7+KFi2qDh06KCEhwelzR48eVZs2bVSkSBGVLl1aQ4cO1eXLl53GrF+/XvXq1ZPdblflypU1b968G6r1amg0AQAACqBt27bp3Xff1T333OO0fdCgQVq2bJkWL16sDRs26NixY2rfvr1jf0ZGhtq0aaO0tDRt2rRJ8+fP17x58zRq1CjHmEOHDqlNmzZq1aqV4uLiNHDgQPXo0UOrV6/O02uwWZZl5ekRC4DzlzLzuwQAAJBLxTzzL/9aueeEsWM/fFfpXH8mOTlZ9erV0zvvvKNx48apTp06mjJlis6dO6dSpUpp4cKFeuKJJyRJ+/btU40aNRQTE6NGjRrp66+/Vtu2bXXs2DEFBARIkmbNmqXhw4fr5MmT8vDw0PDhw7VixQrt3r3bcc6OHTsqMTFRq1atypsLF4kmAACAUampqUpKSnJ6paam/u1nIiIi1KZNG4WGhjptj42NVXp6utP26tWrq3z58oqJiZEkxcTEqFatWo4mU5LCwsKUlJSkPXv2OMb89dhhYWGOY+QVGk0AAODy3GQz9oqKipKvr6/TKyoq6pq1fPrpp9qxY8dVx8THx8vDw0N+fn5O2wMCAhQfH+8Yc2WTmbU/a9/fjUlKStLFixdz/f1dC8sbAQAAGDRixAhFRkY6bbPb7Vcd+9tvv2nAgAGKjo6Wp6fnzSjPKBJNAADg8mw2cy+73S4fHx+n17UazdjYWJ04cUL16tWTu7u73N3dtWHDBk2bNk3u7u4KCAhQWlqaEhMTnT6XkJCgwMBASVJgYGC2p9Cz3v/TGB8fH3l5eeXFVyqJRhMAAMBoo5kb999/v3bt2qW4uDjHq0GDBurcubPjvxcuXFhr1651fGb//v06evSoQkJCJEkhISHatWuXTpz4/wecoqOj5ePjo5o1azrGXHmMrDFZx8grTJ0DAAAUEMWKFdPdd9/ttM3b21v+/v6O7d27d1dkZKRKlCghHx8f9evXTyEhIWrUqJEkqXXr1qpZs6aeffZZjR8/XvHx8XrllVcUERHhSFJ79+6tGTNmaNiwYXruuee0bt06ffbZZ1qxYkWeXg+NJgAAcHk3urD6zTR58mS5ubmpQ4cOSk1NVVhYmN555x3H/kKFCmn58uXq06ePQkJC5O3trfDwcI0dO9YxpmLFilqxYoUGDRqkqVOnqmzZspozZ47CwsLytFbW0QQAAAVCfq6jGb33lLFjP1CjpLFjF3QkmgAAwOW53TqB5i2Fh4EAAABgBIkmAABwebfSPZq3EhJNAAAAGEGiCQAAXF5u17tEztBoAgAAl8fUuRlMnQMAAMAIEk0AAODyWN7IDBJNAAAAGEGiCQAAXB73aJpBogkAAAAjSDRR4Dzy0P06fuxYtu3/eupp9Y7or3ffmaHNMd8rIf64/IqXUMtW96tPRH8VLVbMMTb++DFFvT5G27dtVRGvImr7aDtF9B8kd3f+Jw/kp7/7+x7+0ijHe8uyNCDieW36/lu9NXm6Wv5PqGPf1i0xmvX2NB088LO8vIqozSOP6YV+A/n7xg1heSMz+KtEgfPhgsXKyMxwvP/l4AFFPN9d9z/woE6eOKGTJ09oYOQw3Vmpko4fO6aocaN18uQJjZ84VZKUkZGhAX17y79kSc2dv1CnTp3Uq6+8KHd3d0X0H5RflwVAf//3faWFH8/X1WYyf96/TwMintdzPZ7XmHFv6sSJBEWNG6PMzEwNHDzMdPkAcompcxQ4xUuUUMmSpRyv7zauV9ly5VW/wb2qXKWqJkyapuYtW6lsufK6t2EjvdBvoL7d8I0uX74sSdoc870O/fqLXntjvKpVr6EmTZur9wv99dmihUpPT8vnqwNc29/9fWfZv2+vFnw4T6PGvJ7t89Grv1aVqtXUs3eEypUPVv0G96n/wCFavGihUlJSbual4DZjM/hyZTSaKNDS09O0csUyPdquvWzXmNdITj4v76JFHdNmu36MU+UqVeXvX9IxJqRxU6UkJ+uXgwdvSt0A/tnV/r4vXbyoV0YM1bCXRqpkyVLZPpOWliYPD7vTNrunXampqdr7056bUjduT242m7GXKyvQjeZvv/2m55577m/HpKamKikpyemVmpp6kyqEaevXrVXy+fN65NHHr7o/8exZzZk9U493eNKx7fTpUypRwt9pnL+/v2MfgILhan/fEye8qXtq11HLVvdf9TMhjZtq548/aNXXK5SRkaETCQma8+47kqRTp07elLoB5FyBbjTPnDmj+fPn/+2YqKgo+fr6Or0mTnjzJlUI075c8rkaN2mmUqVLZ9uXnJysAX176847K+v53hH5UB2AG/HXv+8N69dp+7bNGjxsxDU/06hxE/UfNFRR40ar8b211f7Rh9SkaQtJcvnkCDeGqXMz8vVhoK+++upv9//666//eIwRI0YoMjLSaVuaVfiG6kLBcPzYH9q6JUbjJ03Lti8lJUX9X+gpb+8imjB5utwL//8/c3//ktqze5fT+NOnTzv2Ach/V/v73r51s37/7Te1atrQaeywwQNUp159zX7/Q0nSM126qvOz4Tp18qSK+fjo+LE/NGPaJN1RttxNvQYA/yxfG8127drJZrPJsqxrjrnWfXlZ7Ha77Hbn+3XOX8rMk/qQv776comKlyihps1aOG1PTk5Wvz49VNjDQ5OmvpPtn3+t2nU0d867OnP6tEr835T5ls2b5F20qO6sVPmm1Q/g2q729x3+XE899vgTTuM6PvGYIoe8qGYtWjltt9lsjiR09dcrFBBYRtVr1DRfOG5frh49GpKvjWaZMmX0zjvv6LHHHrvq/ri4ONWvX/8mV4WCIDMzU8u+/EJtH2nntDZecnKy+vburkuXLum1N8YrOSVZySnJkqTixUuoUKFCahTSRBXvrKRRLw9X/0FDdPrUKc2cMVVPPtVJHh4e+XVJAP7Ptf6+s55E/6vAMmV0R9myjvcfzntfjZs0k81m0zdrozVv7hy9OWGSChUqdFPqB5Bz+dpo1q9fX7GxsddsNP8p7cTta+vmGMUfP65H27V32r5v70/avWunJKld2zCnfV+t/K+C7rhDhQoV0pTpMxX1+hh16/K0vLy81PaRdnr+hX43rX4A13atv++c2vTdt5o7512lp6WpStVqmjh1hpo0bZ7HVcLV8BOUZtisfOzkvv32W6WkpOjBBx+86v6UlBRt375dLVq0uOr+a2HqHACAW08xz/x7RnnLL+eMHbthJV9jxy7o8rXRNIVGEwCAW09+NppbfzXXaN53p+s2mvwEJQAAcHlMnJtRoNfRBAAAwK2LRBMAAIBI0wgSTQAAABhBogkAAFweyxuZQaIJAAAAI0g0AQCAy/uHX7zGdSLRBAAAgBEkmgAAwOURaJpBowkAAECnaQRT5wAAADCCRBMAALg8ljcyg0QTAAAARpBoAgAAl8fyRmaQaAIAAMAIEk0AAODyCDTNINEEAACAESSaAAAARJpG0GgCAACXx/JGZjB1DgAAACNINAEAgMtjeSMzSDQBAABgBIkmAABweQSaZpBoAgAAwAgSTQAAACJNI0g0AQAAYASJJgAAcHmso2kGiSYAAACMINEEAAAuj3U0zaDRBAAALo8+0wymzgEAAGAEiSYAAACRphEkmgAAADCCRBMAALg8ljcyg0QTAAAARpBoAgAAl8fyRmaQaAIAAMAIEk0AAODyCDTNoNEEAACg0zSCqXMAAAAYQaIJAABcHssbmUGiCQAAACNINAEAgMtjeSMzSDQBAAAKiKioKN17770qVqyYSpcurXbt2mn//v1OYy5duqSIiAj5+/uraNGi6tChgxISEpzGHD16VG3atFGRIkVUunRpDR06VJcvX3Yas379etWrV092u12VK1fWvHnz8vx6aDQBAIDLsxl85caGDRsUERGhzZs3Kzo6Wunp6WrdurVSUlIcYwYNGqRly5Zp8eLF2rBhg44dO6b27ds79mdkZKhNmzZKS0vTpk2bNH/+fM2bN0+jRo1yjDl06JDatGmjVq1aKS4uTgMHDlSPHj20evXqXFb892yWZVl5esQC4PylzPwuAQAA5FIxz/zLv345cdHYsSuV9rruz548eVKlS5fWhg0b1Lx5c507d06lSpXSwoUL9cQTT0iS9u3bpxo1aigmJkaNGjXS119/rbZt2+rYsWMKCAiQJM2aNUvDhw/XyZMn5eHhoeHDh2vFihXavXu341wdO3ZUYmKiVq1adWMXfAUSTQAAAIORZmpqqpKSkpxeqampOSrr3LlzkqQSJUpIkmJjY5Wenq7Q0FDHmOrVq6t8+fKKiYmRJMXExKhWrVqOJlOSwsLClJSUpD179jjGXHmMrDFZx8grNJoAAMDl2Qz+JyoqSr6+vk6vqKiof6wpMzNTAwcOVJMmTXT33XdLkuLj4+Xh4SE/Pz+nsQEBAYqPj3eMubLJzNqfte/vxiQlJenixbxLd3nqHAAAwKARI0YoMjLSaZvdbv/Hz0VERGj37t367rvvTJVmHI0mAABweSaXN7Lb7TlqLK/Ut29fLV++XBs3blTZsmUd2wMDA5WWlqbExESnVDMhIUGBgYGOMVu3bnU6XtZT6VeO+euT6gkJCfLx8ZGX1/XfU/pXTJ0DAAAUEJZlqW/fvlqyZInWrVunihUrOu2vX7++ChcurLVr1zq27d+/X0ePHlVISIgkKSQkRLt27dKJEyccY6Kjo+Xj46OaNWs6xlx5jKwxWcfIKzx1DgAACoT8fOr88KlLxo5doaRnjse+8MILWrhwob788ktVq1bNsd3X19eRNPbp00crV67UvHnz5OPjo379+kmSNm3aJOnP5Y3q1KmjoKAgjR8/XvHx8Xr22WfVo0cPvfHGG5L+XN7o7rvvVkREhJ577jmtW7dO/fv314oVKxQWFpZXl06jCQAACgYaTcl2jTn8Dz74QF27dpX054LtgwcP1ieffKLU1FSFhYXpnXfecUyLS9KRI0fUp08frV+/Xt7e3goPD9ebb74pd/f/v2ty/fr1GjRokH766SeVLVtWI0eOdJwjr9BoAgCAAiFfG83TBhtN/5w3mrcb7tEEAACAETx1DgAAXJ4t1z8WiZyg0QQAAC7P5PJGroypcwAAABhBogkAAFwegaYZJJoAAAAwgkQTAAC4PO7RNINEEwAAAEaQaAIAAHCXphEkmgAAADCCRBMAALg87tE0g0YTAAC4PPpMM5g6BwAAgBEkmgAAwOUxdW4GiSYAAACMINEEAAAuz8ZdmkaQaAIAAMAIEk0AAAACTSNINAEAAGAEiSYAAHB5BJpm0GgCAACXx/JGZjB1DgAAACNINAEAgMtjeSMzSDQBAABgBIkmAAAAgaYRJJoAAAAwgkQTAAC4PAJNM0g0AQAAYASJJgAAcHmso2kGjSYAAHB5LG9kBlPnAAAAMIJEEwAAuDymzs0g0QQAAIARNJoAAAAwgkYTAAAARnCPJgAAcHnco2kGiSYAAACMINEEAAAuj3U0zaDRBAAALo+pczOYOgcAAIARJJoAAMDlEWiaQaIJAAAAI0g0AQAAiDSNINEEAACAESSaAADA5bG8kRkkmgAAADCCRBMAALg81tE0g0QTAAAARpBoAgAAl0egaQaNJgAAAJ2mEUydAwAAwAgSTQAA4PJY3sgMEk0AAAAYQaIJAABcHssbmUGiCQAAACNslmVZ+V0EcL1SU1MVFRWlESNGyG6353c5APIQf9/ArY9GE7e0pKQk+fr66ty5c/Lx8cnvcgDkIf6+gVsfU+cAAAAwgkYTAAAARtBoAgAAwAgaTdzS7Ha7Xn31VR4UAG5D/H0Dtz4eBgIAAIARJJoAAAAwgkYTAAAARtBoAgAAwAgaTQAAABhBo4lb2ttvv60KFSrI09NTDRs21NatW/O7JAA3aOPGjXrkkUcUFBQkm82mpUuX5ndJAK4TjSZuWYsWLVJkZKReffVV7dixQ7Vr11ZYWJhOnDiR36UBuAEpKSmqXbu23n777fwuBcANYnkj3LIaNmyoe++9VzNmzJAkZWZmqly5curXr59efPHFfK4OQF6w2WxasmSJ2rVrl9+lALgOJJq4JaWlpSk2NlahoaGObW5ubgoNDVVMTEw+VgYAALLQaOKWdOrUKWVkZCggIMBpe0BAgOLj4/OpKgAAcCUaTQAAABhBo4lbUsmSJVWoUCElJCQ4bU9ISFBgYGA+VQUAAK5Eo4lbkoeHh+rXr6+1a9c6tmVmZmrt2rUKCQnJx8oAAEAW9/wuALhekZGRCg8PV4MGDXTfffdpypQpSklJUbdu3fK7NAA3IDk5WQcPHnS8P3TokOLi4lSiRAmVL18+HysDkFssb4Rb2owZMzRhwgTFx8erTp06mjZtmho2bJjfZQG4AevXr1erVq2ybQ8PD9e8efNufkEArhuNJgAAAIzgHk0AAAAYQaMJAAAAI2g0AQAAYASNJgAAAIyg0QQAAIARNJoAAAAwgkYTAAAARtBoAgAAwAgaTQDXrWvXrmrXrp3jfcuWLTVw4MCbXsf69etls9mUmJho7Bx/vdbrcTPqBICChEYTuM107dpVNptNNptNHh4eqly5ssaOHavLly8bP/cXX3yh1157LUdjb3bTVaFCBU2ZMuWmnAsA8Cf3/C4AQN578MEH9cEHHyg1NVUrV65URESEChcurBEjRmQbm5aWJg8Pjzw5b4kSJfLkOACA2wOJJnAbstvtCgwMVHBwsPr06aPQ0FB99dVXkv5/Cvj1119XUFCQqlWrJkn67bff9OSTT8rPz08lSpTQY489psOHDzuOmZGRocjISPn5+cnf31/Dhg2TZVlO5/3r1HlqaqqGDx+ucuXKyW63q3Llynr//fd1+PBhtWrVSpJUvHhx2Ww2de3aVZKUmZmpqKgoVaxYUV5eXqpdu7b+85//OJ1n5cqVqlq1qry8vNSqVSunOq9HRkaGunfv7jhntWrVNHXq1KuOHTNmjEqVKiUfHx/17t1baWlpjn05qf1KR44c0SOPPKLixYvL29tbd911l1auXHlD1wIABQmJJuACvLy8dPr0acf7tWvXysfHR9HR0ZKk9PR0hYWFKSQkRN9++63c3d01btw4Pfjgg9q5c6c8PDw0ceJEzZs3T3PnzlWNGjU0ceJELVmyRP/zP/9zzfN26dJFMTExmjZtmmrXrq1Dhw7p1KlTKleunD7//HN16NBB+/fvl4+Pj7y8vCRJUVFR+vjjjzVr1ixVqVJFGzdu1DPPPKNSpUqpRYsW+u2339S+fXtFRESoV69e2r59uwYPHnxD309mZqbKli2rxYsXy9/fX5s2bVKvXr1UpkwZPfnkk07fm6enp9avX6/Dhw+rW7du8vf31+uvv56j2v8qIiJCaWlp2rhxo7y9vfXTTz+paNGiN3QtAFCgWABuK+Hh4dZjjz1mWZZlZWZmWtHR0ZbdbreGDBni2B8QEGClpqY6PvPRRx9Z1apVszIzMx3bUlNTLS8vL2v16tWWZVlWmTJlrPHjxzv2p6enW2XLlnWcy7Isq0WLFtaAAQMsy7Ks/fv3W5Ks6Ojoq9b5zTffWJKss2fPOrZdunTJKlKkiLVp0yansd27d7eefvppy7Isa8SIEVbNmjWd9g8fPjzbsf4qODjYmjx58jX3/1VERITVoUMHx/vw8HCrRIkSVkpKimPbzJkzraJFi1oZGRk5qv2v11yrVi1r9OjROa4JAG41JJrAbWj58uUqWrSo0tPTlZmZqU6dOmn06NGO/bVq1XK6L/PHH3/UwYMHVaxYMafjXLp0Sb/88ovOnTun48ePq2HDho597u7uatCgQbbp8yxxcXEqVKjQVZO8azl48KAuXLigBx54wGl7Wlqa6tatK0nau3evUx2SFBISkuNzXMvbb7+tuXPn6ujRo7p48aLS0tJUp04dpzG1a9dWkSJFnM6bnJys3377TcnJyf9Y+1/1799fffr00Zo1axQaGqoOHTronnvuueFrAYCCgkYTuA21atVKM2fOlIeHh4KCguTu7vyn7u3t7fQ+OTlZ9evX14IFC7Idq1SpUtdVQ9ZUeG4kJydLklasWKE77rjDaZ/dbr+uOnLi008/1ZAhQzRx4kSFhISoWLFimjBhgrZs2ZLjY1xP7T169FBYWJhWrFihNWvWKCoqShMnTlS/fv2u/2IAoACh0QRuQ97e3qpcuXKOx9erV0+LFi1S6dKl5ePjc9UxZcqU0ZYtW9S8eXNJ0uXLlxUbG6t69epddXytWrWUmZmpDRs2KDQ0NNv+rEQ1IyPDsa1mzZqy2+06evToNZPQGjVqOB5syrJ58+Z/vsi/8f3336tx48Z64YUXHNt++eWXbON+/PFHXbx40dFEb968WUWLFlW5cuVUokSJf6z9asqVK6fevXurd+/eGjFihN577z0aTQC3DZ46B6DOnTurZMmSeuyxx/Ttt9/q0KFDWr9+vfr376/ff/9dkjRgwAC9+eabWrp0qfbt26cXXnjhb9fArFChgsLDw/Xcc89p6dKljmN+9tlnkqTg4GDZbDYtX75cJ0+eVHJysooVK6YhQ4Zo0KBBmj9/vn755Rft2LFD06dP1/z58yVJvXv31oEDBzR06FDt379fCxcu1Lx583J0nX/88Yfi4uKcXmfPnlWVKlW0fft2rV69Wj///LNGjhypbdu2Zft8Wlqaunfvrp9++kkrV67Uq6++qr59+8rNzS1Htf/VwIEDtXr1ah06dEg7duzQN998oxo1auToWgDglpDfN4kCyFtXPgyUm/3Hjx+3unTpYpUsWdKy2+3WnXfeafXs2dM6d+6cZVl/PvwzYMAAy8fHx/Lz87MiIyOtLl26XPNhIMuyrIsXL1qDBg2yypQpY3l4eFiVK1e25s6d69g/duxYKzAw0LLZbFZ4eLhlWX8+wDRlyhSrWrVqVuHCha1SpUpZYWFh1oYNGxyfW7ZsmVW5cmXLbrdbzZo1s+bOnZujh4EkZXt99NFH1qVLl6yuXbtavr6+lp+fn9WnTx/rxRdftGrXrp3texs1apTl7+9vFS1a1OrZs6d16dIlx5h/qv2vDwP17dvXqlSpkmW3261SpUpZzz77rHXq1KlrXgMA3GpslnWNO/kBAACAG8DUOQAAAIyg0QQAAIARNJoAAAAwgkYTAAAARtBoAgAAwAgaTQAAABhBowkAAAAjaDQBAABgBI0mAAAAjKDRBAAAgBE0mgAAADDifwEeNH62x23giwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}